mean(my.sample) > my.conf.int[1] & mean(my.sample) < my.conf.int[2]
#YES, the true population mean is within the confidence interval of my sample mean
#PC2.
#Let's look beyond the mean.
#Compare the distribution from your sample of x to the true population.
#Draw histograms and compute other descriptive and summary statistics.
#What do you notice? Be ready to talk for a minute or two about the differences.
summary(population$x)
summary(my.sample)
hist((population$x))
hist((my.sample))
#The population has a much lower min. and a larger max, and it's more normal.
#PC3.
#Compute the mean of y from the true population and then create the mean and confidence interval
#from the y in your sample. Is it in or out?
#Oops, just realized I've been working from the week2 dataset instead of week3, which does
#actually have a y variable. So have to load that one up.
#Pass it into a new variable (#This is going to get messy since I don't have x and y in the same variable)
week3.dataset <- read.csv("week3_dataset-anissa.csv")
head(week3.dataset)
my.sample.y <- week3.dataset$y
#Find the mean of my.sample
mean(my.sample.y)
#(a) compute the confidence interval by hand
my.conf.int.y <- mean(my.sample.y) + (1.96 * sd(my.sample.y) / sqrt(length(my.sample.y))) * c(-1, 1)
my.conf.int.y
#(b) find the confidence interval using an r function
t.test(my.sample.y)
#As to why they aren't they the same .... can't answer yet, haven't read OpenIntro
#(c) is the true population mean within the confidence interval of my.sample.y?
mean(my.sample.y) > my.conf.int.y[1] & mean(my.sample.y) < my.conf.int.y[2]
# TRUE, so yes, it's within the confidence interval
#PC4.
#I want you to run a simple simulation that demonstrates one of the most fundamental
#insights of statistics:
#(a) Create a vector of 10,000 randomly generated numbers that are uniformly distributed between 0 and 9.
#(b) Take the mean of that vector. Draw a histogram.
#(c) Create 100 random samples of 2 items each from your randomly generated data and take the mean of each sample.
#Create a new vector that contains those means. Describe/display the distribution of those means.
#(d) Do (c) except make the items 10 items in each sample instead of 2. Then do (c) again except with 100 items.
#Be ready to describe how the histogram changes as the sample size increases.
#(HINT: You'll make me very happy if you write a function to do this.)
#(a) First create the vector in a new variable then look take a look at the beginning
random.vector <- runif(n=10000, min=0, max=9)
head(random.vector)
#(b) Mean and histogram
mean(random.vector)
hist(random.vector)
#(c) 100 random samples of the 2 items from the random vector
find.sample.mean.2 <- function(i) {
new.sample <- sample(random.vector, 2)
mean(new.sample)
}
sample.means.2 <- sapply(rep(1, 100), find.sample.mean.2)
summary(sample.means.2)
hist(sample.means.2)
#(d) Repeat with 10 items 100 times
find.sample.mean.10 <- function(i) {
new.sample <- sample(random.vector, 10)
mean(new.sample)
}
sample.means.10 <- sapply(rep(1, 100), find.sample.mean.10)
# Repeat with 100 items 100 times
find.sample.mean.100 <- function(i) {
new.sample <- sample(random.vector, 100)
mean(new.sample)
}
sample.means.100 <- sapply(rep(1, 100), find.sample.mean.100)
#Compare the summary statistics and histograms of each of these sampling distributions
summary(sample.means.2)
summary(sample.means.10)
summary(sample.means.100)
hist(sample.means.2)
hist(sample.means.10)
hist(sample.means.100)
#It's not as distributed ... the min and max are much closer together. Better distributed around the true mean.
#PC5.
#Do PC4 again but with random data drawn from a normal distribution (mu = 42, sigma = 42)
#instead of a uniform distribution. How are you results different than in PC4?
#(a) First create the vector in a new variable then look take a look at the beginning
random.vector.2 <- rnorm(n=10000, mean=42, sd=42)
head(random.vector.2)
#(b) Mean and histogram
mean(random.vector.2)
hist(random.vector.2)
#(c) 100 random samples of the 2 items from the random vector
find.sample.mean.2 <- function(i) {
new.sample <- sample(random.vector.2, 2)
mean(new.sample)
}
sample.means.2 <- sapply(rep(1, 100), find.sample.mean.2)
summary(sample.means.2)
hist(sample.means.2)
#(d) Repeat with 10 items 100 times
find.sample.mean.10 <- function(i) {
new.sample <- sample(random.vector.2, 10)
mean(new.sample)
}
sample.means.10 <- sapply(rep(1, 100), find.sample.mean.10)
# Repeat with 100 items 100 times
find.sample.mean.100 <- function(i) {
new.sample <- sample(random.vector.2, 100)
mean(new.sample)
}
sample.means.100 <- sapply(rep(1, 100), find.sample.mean.100)
#Compare the summary statistics and histograms of each of these sampling distributions
summary(sample.means.2)
summary(sample.means.10)
summary(sample.means.100)
hist(sample.means.2)
hist(sample.means.10)
hist(sample.means.100)
#This time the sampling distribution is a closer representation of the population data
#because the population data was itself normally distributed.
#First I tried the built-in t.test() function, putting the difference between means as the x value:
#t.test(12.3, mu=0, alternative = "greater", paired = FALSE, conf.level = .95)
#Doesn't work because I don't have the original data in the form of a vector
#Found this on stack overflow:
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- (m1-m2-m0)/se
dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
return(dat)
}
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
#This gives me a different t score than what I got by hand
#I think they may have calculated the t score wrong: t <- (m1-m2-m0)/se
#I found this formula for the t-score:
#t <- abs(qt(0.05/2, 44)) # 95% confidence, 2 sided
#So I'm going to try substituting that in the code above
#First I tried the built-in t.test() function, putting the difference between means as the x value:
#t.test(12.3, mu=0, alternative = "greater", paired = FALSE, conf.level = .95)
#Doesn't work because I don't have the original data in the form of a vector
#Found this on stack overflow:
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
return(dat)
}
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
#That worked, but now I want to add a confidence interval
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), (((m1-m2) + (t*se)) ((m1-m2) - (t*se))))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "confidence interval")
return(dat)
}
t <- (m1-m2-m0)/se
dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
return(dat)
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
m1 <- 56.81
m2 <- 44.51
s1 <- 16.13
s2 <- 13.32
n1 <- 23
n2 <- 23
m0 <- 0
equal.variance = FALSE
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
t
dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), (((m1-m2) + (t*se)) ((m1-m2) - (t*se))))
m1-m2
m1-m2 - t*se
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) + (t*se)), ((m1-m2) - (t*se)))
dat
#That worked, but now I want to add a confidence interval
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) + (t*se)), ((m1-m2) - (t*se)))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "confidence interval")
return(dat)
}
t <- (m1-m2-m0)/se
dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
return(dat)
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) + (t*se)), ((m1-m2) - (t*se)))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "confidence interval")
return(dat)
}
t <- (m1-m2-m0)/se
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
#That worked, but now I want to add a confidence interval
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) + (t*se)), ((m1-m2) - (t*se)))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "confidence interval")
return(dat)
}
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
#That worked, but now I want to add a confidence interval
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1+n2-2))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) - (t*se)), ((m1-m2) + (t*se)))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "Conf Int Min", "Conf Int Max")
return(dat)
}
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
#That worked, but now I want to add a confidence interval
# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0.
# equal.variance: whether or not to assume equal variance. Default is FALSE.
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
if( equal.variance==FALSE )
{
se <- sqrt( (s1^2/n1) + (s2^2/n2) )
# welch-satterthwaite df
df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
} else
{
# pooled standard deviation, scaled by the sample sizes
se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) )
df <- n1+n2-2
}
t <- abs(qt(0.05/2, (n1-1))) # 95% confidence, 2 sided, had to put the formula for df in
dat <- c((m1-m2), se, t, 2*pt(-abs(t),df), ((m1-m2) - (t*se)), ((m1-m2) + (t*se)))
names(dat) <- c("Difference of means", "Std Error", "t", "p-value", "Conf Int Min", "Conf Int Max")
return(dat)
}
#For my data:
#m1 <- 56.81
#m2 <- 44.51
#s1 <- 16.13
#s2 <- 13.32
#n1 <- 23
#n2 <- 23
#m0 <- 0
#equal.variance = FALSE
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
Difference of means           Std Error                   t             p-value        Conf Int Min
12.300000            4.361887            2.015368            0.050000            3.509195
Conf Int Max
21.090805
t.test2(56.81,44.51,16.13,13.32,23,23,m0=0,equal.variance=TRUE)
Difference of means           Std Error                   t             p-value        Conf Int Min
12.300000            4.361887            2.015368            0.050000            3.509195
Conf Int Max
21.090805
sq((.48*.52)/1259)
sqrt((.48*.52)/1259)
.48-1.96*.014
.48+1.96*.014
.48*.52
1.96*.02
.0392^2
.25/.0015
1.96*.014
.48*.52
.02*1.96
.0392^2
.25/.0015
.04*1.96
.5*.5
.0784^2
.25/.0061
.02/1.96
.0102^2
.25/.0001
.04/1.96
.0204^2
.25/.0004
.04/1.96
0.02040816^2
.25/0.000416493
.25/.0004
329/500
171/500
500*.18
.22*500
.37*500
.23*500
(83-90)^2
(121-110)^2
11^2
(193-185)^2
(103-115)^2
(49/90)+(121/110)+(64/185)+(144/115)
171/500
329/500
83*.34
121*.34
193*.34
103*.34
28+41+66+35
171/500
329/500
83*.342
121*.342
193*.342
103*.342
83*.658
121*.658
193*.658
103*.658
55+80+127+68
(54-55)^2/55
(77-80)^2/80
(131-127)^2/127
(67-68)^2/68
.018+.113+.126+.015
54-55
-1^2
(-1)^2
1/55
9/80
16/127
1/68
rm(list = ls())
